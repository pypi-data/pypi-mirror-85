# Terminus environment variable
TERMINUS_HOSTNAME="__empty__"
TERMINUS_DOT_DIR="__empty__"
TERMINUS_DATA_DIR="__empty__"
TERMINUS_JOB_DIR="__empty__"

TERMINUS_ROOT="__empty__"
TERMINUS_SERVICE_DIR="__empty__"

TERMINUS_USE_SLURM=0

GALACSTORAGE_SSH_ALIAS="Galactica_storage"
RABBITMQ_USERNAME="__empty__"
RABBITMQ_HOST="__empty__"
RABBITMQ_PORT="__empty__"
RABBITMQ_VIRTUAL_HOST="__empty__"

PATH=/usr/bin

# Celery configuration
# Name of nodes to start : here we have 4 nodes
# CELERYD_NODES="w1@host w2@host w3@host w4@host"
# or we could have named nodes:
# CELERYD_NODES="w1@machine w2@machine w3@machine w4@machine"
CELERYD_NODES=4

# Absolute or relative path to the 'celery' command:
CELERY_BIN="__empty__"

# App instance to use
# comment out this line if you don't use an app
CELERY_APP="Terminus"
# or fully qualified:
#CELERY_APP="Terminus.tasks:app"

# How to call manage.py
CELERYD_MULTI="multi"

# Extra command-line arguments to the worker : listen to the host-specific terminus job queue
# queue.
CELERYD_OPTS="--concurrency=4 -Q hostname.terminus_jobs"

# - %n will be replaced with the first part of the nodename.
# - %I will be replaced with the current child process index
#   and is important when using the prefork pool to avoid race conditions.
CELERYD_PID_FILE="__empty__"
CELERYD_LOG_FILE="__empty__"
CELERYD_LOG_LEVEL="INFO"

# PID and LOG directories will be created if missing
CELERY_CREATE_DIRS=1
