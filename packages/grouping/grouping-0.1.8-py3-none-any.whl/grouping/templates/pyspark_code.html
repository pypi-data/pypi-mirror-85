{% extends "layout.html" %}
{% block body %}


                        <h2>Replace df with the dataframe variable you use</h2>
                        <p>from itertools import chain</p>
                        <p>from pyspark.sql.functions import coalesce,lit, col, create_map</p>
                        <h3>Map only changed grouping values</h3>
                        <p>map_values = {{final_part}}</p>
                        <p>mapping_expr  = create_map([lit(x) for x in chain(*map_values.items())])</p>
                        <p>df=df.withColumn({{col2}}, coalesce(mapping_expr[df[{{col1}}]], df[{{col2}}]))</p>
                        <h3>Map all grouing values</h3>
                        <p>map_values = {{final_all}}</p>
                        <p>mapping_expr  = create_map([lit(x) for x in chain(*map_values.items())])</p>
                        <p>df=df.withColumn({{col2}}, coalesce(mapping_expr[df[{{col1}}]], lit(-1)))</p>





{% endblock %}
