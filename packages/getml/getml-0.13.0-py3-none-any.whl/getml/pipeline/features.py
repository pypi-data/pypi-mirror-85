# Copyright 2020 The SQLNet Company GmbH

# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to
# deal in the Software without restriction, including without limitation the
# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
# sell copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:

# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.

# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
# DEALINGS IN THE SOFTWARE.

"""
Custom class for handling the features of a pipeline.
"""

import json

import pandas as pd
import numpy as np

import getml.communication as comm

from getml.data.helpers import (
    _is_typed_list
)

from .helpers import _attach_empty

from .sql_code import SQLCode


class Features():
    """
    Custom class for handling the
    features generated by the pipeline.

    Example:

        .. code-block:: python

            names, importances = my_pipeline.features.importances()

            names, correlations = my_pipeline.features.correlations()

            sql_code = my_pipeline.features.to_sql()
    """

    # ----------------------------------------------------------------

    def __init__(self, name, targets):

        if not isinstance(name, str):
            raise ValueError(
                "'name' must be a str.")

        if not _is_typed_list(targets, str):
            raise TypeError(
                "'targets' must be a list of str.")

        self.name = name

        self.targets = targets

    # ----------------------------------------------------------------

    def _to_pandas(self, target_num, target_name):

        names, correlations = self.correlations(
            target_num=target_num,
            sort=False)

        names, importances = self.importances(
            target_num=target_num,
            sort=False)

        sql_code = self.to_sql()

        code = [sql_code[name].to_str() for name in names
                if name[:8] == "feature_"]

        max_length = np.max([
            len(names),
            len(correlations),
            len(importances),
            len(code)
        ])

        data_frame = pd.DataFrame(
            index=np.arange(max_length)
        )

        data_frame["names"] = _attach_empty(
            names.tolist(), max_length, "--")

        data_frame["correlations"] = _attach_empty(
            correlations.tolist(), max_length, np.NaN)

        data_frame["importances"] = _attach_empty(
            importances.tolist(), max_length, np.NaN)

        data_frame["target"] = [target_name] * max_length

        data_frame["sql"] = _attach_empty(
            code, max_length, "--")

        return data_frame

    # ----------------------------------------------------------------

    def correlations(self, target_num=0, sort=True):
        """
        Returns the data for the feature correlations,
        as displayed in the getML monitor.

        Args:
            target_num (int):
                Indicates for which target you want to view the
                importances.
                (Pipelines can have more than one target.)

            sort (bool):
                Whether you want the results to be sorted.

        Return:
            (:class:`numpy.ndarray`, :class:`numpy.ndarray`):
                - The first array contains the names of
                  the features.
                - The second array contains the correlations with
                  the target.
        """

        # ------------------------------------------------------------

        cmd = dict()

        cmd["type_"] = "Pipeline.feature_correlations"
        cmd["name_"] = self.name

        cmd["target_num_"] = target_num

        # ------------------------------------------------------------

        sock = comm.send_and_receive_socket(cmd)

        msg = comm.recv_string(sock)

        if msg != "Success!":
            comm.engine_exception_handler(msg)

        # ------------------------------------------------------------

        msg = comm.recv_string(sock)

        json_obj = json.loads(msg)

        # ------------------------------------------------------------

        names = np.asarray(json_obj["feature_names_"])
        correlations = np.asarray(json_obj["feature_correlations_"])

        # ------------------------------------------------------------

        if not sort:
            return names, correlations

        # ------------------------------------------------------------

        indices = np.argsort(np.abs(correlations))[::-1]

        # ------------------------------------------------------------

        return (
            names[indices],
            correlations[indices]
        )

    # ----------------------------------------------------------------

    def importances(self, target_num=0, sort=True):
        """
        Returns the data for the feature importances,
        as displayed in the getML monitor.

        Args:
            target_num (int):
                Indicates for which target you want to view the
                importances.
                (Pipelines can have more than one target.)

            sort (bool):
                Whether you want the results to be sorted.

        Return:
            (:class:`numpy.ndarray`, :class:`numpy.ndarray`):
                - The first array contains the names of
                  the features.
                - The second array contains their importances.
                  By definition, all importances add up to 1.
        """

        # ------------------------------------------------------------

        cmd = dict()

        cmd["type_"] = "Pipeline.feature_importances"
        cmd["name_"] = self.name

        cmd["target_num_"] = target_num

        # ------------------------------------------------------------

        sock = comm.send_and_receive_socket(cmd)

        msg = comm.recv_string(sock)

        if msg != "Success!":
            comm.engine_exception_handler(msg)

        # ------------------------------------------------------------

        msg = comm.recv_string(sock)

        json_obj = json.loads(msg)

        # ------------------------------------------------------------

        names = np.asarray(json_obj["feature_names_"])
        importances = np.asarray(json_obj["feature_importances_"])

        # ------------------------------------------------------------

        if not sort:
            return names, importances

        # ------------------------------------------------------------

        indices = np.argsort(importances)[::-1]

        # ------------------------------------------------------------

        return (
            names[indices],
            importances[indices]
        )

    # ----------------------------------------------------------------

    def to_pandas(self):
        """Returns all information related to the features
           in a pandas data frame."""

        data_frame = None

        for t_num, t_name in enumerate(self.targets):
            current_df = self._to_pandas(t_num, t_name)

            if data_frame is None:
                data_frame = current_df
                continue

            data_frame = pd.concat(
                [data_frame, current_df],
                ignore_index=True
            )

        return data_frame

    # ----------------------------------------------------------------

    def to_sql(self, targets=True):
        """Returns SQL statements visualizing the features.

        Args:
            targets (boolean):
                Whether you want to include the target columns
                in the main table.

        Examples:

            .. code-block:: python

                my_pipeline.features.to_sql()

        Raises:
            IOError: If the pipeline could not be found
                on the engine or
                the pipeline could not be fitted.
            KeyError: If an unsupported instance variable is
                encountered .
            TypeError: If any instance variable is of wrong type.

        Returns:
            :class:`~getml.pipeline.SQLCode`
                Object representing the features.

        Note:
            Only fitted pipelines
            (:meth:`~getml.pipeline.Pipeline.fit`) can hold trained
            features which can be returned as SQL statements.
            The dialect is based on the SQLite3 standard.
        """

        # ------------------------------------------------------------

        cmd = dict()
        cmd["type_"] = "Pipeline.to_sql"
        cmd["name_"] = self.name

        cmd["targets_"] = targets

        sock = comm.send_and_receive_socket(cmd)

        # ------------------------------------------------------------

        msg = comm.recv_string(sock)

        if msg != "Found!":
            comm.engine_exception_handler(msg)

        # ------------------------------------------------------------

        sql = comm.recv_string(sock)

        # ------------------------------------------------------------

        sock.close()

        # ------------------------------------------------------------

        return SQLCode(sql.split("\n\n\n"))
